#!/usr/bin/env python3
"""
ë‚˜ë¹„ì–Œ ì±—ë´‡ í•™ìŠµ ì‹¤í–‰ íŒŒì¼
KoAlpaca íŒŒì¸íŠœë‹ ë° ê°œì¸í™” í•™ìŠµ
"""

import sys
import os
import logging
import time
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from utils.config import parse_config, get_config_summary
from data.data_loader import NaviyamDataLoader, generate_training_data
from data.data_structure import TrainingData, IntentType, ExtractedEntity
from models.koalpaca_model import KoAlpacaModel
from models.models_config import ModelConfigManager
from training.data_generator import NaviyamDataGenerator
from training.trainer import NaviyamTrainer
from training.fine_tuner import NaviyamFineTuner


def setup_logging(config):
    """ë¡œê¹… ì„¤ì •"""
    log_level = getattr(logging, config.log_level.upper())

    # í•™ìŠµìš© ë¡œê·¸ íŒŒì¼
    log_file = Path(config.data.output_path) / f'training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(log_file, encoding='utf-8')
        ]
    )

    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    logging.getLogger('transformers').setLevel(logging.WARNING)
    logging.getLogger('torch').setLevel(logging.WARNING)
    logging.getLogger('datasets').setLevel(logging.WARNING)

    return logging.getLogger(__name__)


class TrainingPipeline:
    """í•™ìŠµ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, config, logger):
        self.config = config
        self.logger = logger

        # ì»´í¬ë„ŒíŠ¸ë“¤
        self.data_loader = None
        self.knowledge = None
        self.data_generator = None
        self.model = None
        self.trainer = None
        self.fine_tuner = None

        # í•™ìŠµ í†µê³„
        self.training_stats = {
            "start_time": None,
            "end_time": None,
            "total_training_data": 0,
            "epochs_completed": 0,
            "best_loss": float('inf'),
            "final_accuracy": 0.0
        }

    def run_full_pipeline(self):
        """ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ ë‚˜ë¹„ì–Œ ì±—ë´‡ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        self.training_stats["start_time"] = datetime.now()

        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            self._prepare_data()

            # 2. í•™ìŠµ ë°ì´í„° ìƒì„±
            self._generate_training_data()

            # 3. ëª¨ë¸ ì´ˆê¸°í™”
            self._initialize_model()

            # 4. ê¸°ë³¸ í•™ìŠµ (ì˜ë„ ë¶„ë¥˜, ì—”í‹°í‹° ì¶”ì¶œ)
            self._train_basic_components()

            # 5. íŒŒì¸íŠœë‹ (ë„ë©”ì¸ íŠ¹í™”)
            if self.config.training.epochs > 0:
                self._fine_tune_model()

            # 6. í‰ê°€
            self._evaluate_model()

            # 7. ëª¨ë¸ ì €ì¥
            self._save_trained_model()

            self.training_stats["end_time"] = datetime.now()
            self._print_training_summary()

            return 0

        except Exception as e:
            self.logger.error(f"í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            raise

    def _prepare_data(self):
        """ë°ì´í„° ì¤€ë¹„"""
        self.logger.info("ğŸ“Š 1. ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        self.data_loader = NaviyamDataLoader(self.config.data, self.config.debug)

        # ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ
        self.knowledge = self.data_loader.load_all_data()

        self.logger.info(f"   âœ… ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ: "
                         f"ê°€ê²Œ {len(self.knowledge.shops)}ê°œ, "
                         f"ë©”ë‰´ {len(self.knowledge.menus)}ê°œ, "
                         f"ë¦¬ë·° {len(self.knowledge.reviews)}ê°œ")

        # ë°ì´í„° ê²€ì¦
        if len(self.knowledge.shops) == 0:
            raise ValueError("ê°€ê²Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        if len(self.knowledge.menus) == 0:
            raise ValueError("ë©”ë‰´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

    def _generate_training_data(self):
        """í•™ìŠµ ë°ì´í„° ìƒì„±"""
        self.logger.info("ğŸ”§ 2. í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")

        # ë°ì´í„° ìƒì„±ê¸° ì´ˆê¸°í™”
        self.data_generator = NaviyamDataGenerator(self.knowledge)

        # ê¸°ë³¸ ëŒ€í™”ìŒ ìƒì„±
        basic_conversations = self.data_generator.generate_basic_conversations()
        self.logger.info(f"   âœ… ê¸°ë³¸ ëŒ€í™”ìŒ: {len(basic_conversations)}ê°œ ìƒì„±")

        # ë‚˜ë¹„ì–Œ íŠ¹í™” ëŒ€í™”ìŒ ìƒì„±
        naviyam_conversations = self.data_generator.generate_naviyam_specific_conversations()
        self.logger.info(f"   âœ… ë‚˜ë¹„ì–Œ íŠ¹í™” ëŒ€í™”ìŒ: {len(naviyam_conversations)}ê°œ ìƒì„±")

        # ê¸°ì¡´ ë¦¬ë·° ê¸°ë°˜ ëŒ€í™”ìŒ
        review_conversations = self.data_loader.get_training_conversations()
        self.logger.info(f"   âœ… ë¦¬ë·° ê¸°ë°˜ ëŒ€í™”ìŒ: {len(review_conversations)}ê°œ ìƒì„±")

        # ì „ì²´ í•™ìŠµ ë°ì´í„° í†µí•©
        all_training_data = basic_conversations + naviyam_conversations + review_conversations

        # ë°ì´í„° ì¦ê°• (ì„ íƒì )
        if not self.config.debug:
            augmented_data = self.data_generator.augment_data(all_training_data[:100])  # ìƒ˜í”Œë§Œ
            self.logger.info(f"   âœ… ë°ì´í„° ì¦ê°•: {len(augmented_data)}ê°œ ì¶”ê°€")
            all_training_data.extend(augmented_data)

        self.training_stats["total_training_data"] = len(all_training_data)
        self.logger.info(f"   ğŸ¯ ì´ í•™ìŠµ ë°ì´í„°: {len(all_training_data)}ê°œ")

        # í•™ìŠµ ë°ì´í„° ì €ì¥
        self._save_training_data(all_training_data)

        return all_training_data

    def _save_training_data(self, training_data: List[TrainingData]):
        """í•™ìŠµ ë°ì´í„° ì €ì¥"""
        output_dir = Path(self.config.data.output_path) / "training_data"
        output_dir.mkdir(exist_ok=True)

        # JSON í˜•íƒœë¡œ ì €ì¥
        data_list = []
        for data in training_data:
            data_dict = {
                "input_text": data.input_text,
                "target_intent": data.target_intent.value,
                "target_entities": {
                    "food_type": data.target_entities.food_type,
                    "budget": data.target_entities.budget,
                    "companions": data.target_entities.companions
                } if data.target_entities else {},
                "expected_response": data.expected_response,
                "domain": data.domain
            }
            data_list.append(data_dict)

        output_file = output_dir / f"training_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data_list, f, ensure_ascii=False, indent=2)

        self.logger.info(f"   ğŸ’¾ í•™ìŠµ ë°ì´í„° ì €ì¥: {output_file}")

    def _initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        self.logger.info("ğŸ¤– 3. ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")

        # ëª¨ë¸ ì„¤ì • ê´€ë¦¬ì
        config_manager = ModelConfigManager(self.config.model)

        # í•˜ë“œì›¨ì–´ í˜¸í™˜ì„± í™•ì¸
        is_compatible, warnings = config_manager.validate_config()
        if warnings:
            for warning in warnings:
                self.logger.warning(f"   âš ï¸  {warning}")

        if not is_compatible:
            raise RuntimeError("í•˜ë“œì›¨ì–´ í˜¸í™˜ì„± ë¬¸ì œë¡œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # KoAlpaca ëª¨ë¸ ë¡œë“œ
        self.model = KoAlpacaModel(self.config.model, config_manager)
        self.model.load_model(self.config.data.cache_dir)

        # LoRA ì„¤ì •
        self.model.setup_lora()

        self.logger.info("   âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        memory_info = config_manager.monitor_memory_usage()
        self.logger.info(f"   ğŸ“Š GPU ë©”ëª¨ë¦¬: {memory_info.get('gpu_allocated', 0):.1f}GB ì‚¬ìš©")

    def _train_basic_components(self):
        """ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ í•™ìŠµ"""
        self.logger.info("ğŸ“š 4. ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ í•™ìŠµ ì¤‘...")

        # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
        self.trainer = NaviyamTrainer(
            model=self.model,
            config=self.config.training
        )

        # ì˜ë„ ë¶„ë¥˜ê¸° í•™ìŠµ
        intent_accuracy = self.trainer.train_intent_classifier(self.knowledge)
        self.logger.info(f"   âœ… ì˜ë„ ë¶„ë¥˜ê¸° ì •í™•ë„: {intent_accuracy:.1%}")

        # ì—”í‹°í‹° ì¶”ì¶œê¸° í•™ìŠµ
        entity_f1 = self.trainer.train_entity_extractor(self.knowledge)
        self.logger.info(f"   âœ… ì—”í‹°í‹° ì¶”ì¶œê¸° F1: {entity_f1:.3f}")

    def _train_basic_components(self):
        """ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ í•™ìŠµ"""
        self.logger.info("ğŸ“š 4. ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ í•™ìŠµ ì¤‘...")

        # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
        self.trainer = NaviyamTrainer(
            model=self.model,
            config=self.config.training
        )

        # ì˜ë„ ë¶„ë¥˜ê¸° í•™ìŠµ
        intent_accuracy = self.trainer.train_intent_classifier(self.knowledge)
        self.logger.info(f"   âœ… ì˜ë„ ë¶„ë¥˜ê¸° ì •í™•ë„: {intent_accuracy:.1%}")

        # ì—”í‹°í‹° ì¶”ì¶œê¸° í•™ìŠµ
        entity_f1 = self.trainer.train_entity_extractor(self.knowledge)
        self.logger.info(f"   âœ… ì—”í‹°í‹° ì¶”ì¶œê¸° F1: {entity_f1:.3f}")

        # ê¸°ë³¸ ì„±ëŠ¥ ê¸°ë¡
        self.training_stats["intent_accuracy"] = intent_accuracy
        self.training_stats["entity_f1"] = entity_f1

    def _fine_tune_model(self):
        """ëª¨ë¸ íŒŒì¸íŠœë‹"""
        self.logger.info("ğŸ”¥ 5. KoAlpaca íŒŒì¸íŠœë‹ ì¤‘...")

        # íŒŒì¸íŠœë„ˆ ì´ˆê¸°í™”
        self.fine_tuner = NaviyamFineTuner(
            model=self.model,
            config=self.config
        )

        # ë„ë©”ì¸ íŠ¹í™” íŒŒì¸íŠœë‹
        training_loss = self.fine_tuner.fine_tune_domain_specific(self.knowledge)
        self.logger.info(f"   âœ… ë„ë©”ì¸ íŒŒì¸íŠœë‹ ì™„ë£Œ, ìµœì¢… ì†ì‹¤: {training_loss:.4f}")

        self.training_stats["epochs_completed"] = self.config.training.epochs
        self.training_stats["best_loss"] = training_loss

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        self.model.cleanup_memory()

    def _evaluate_model(self):
        """ëª¨ë¸ í‰ê°€"""
        self.logger.info("ğŸ“Š 6. ëª¨ë¸ í‰ê°€ ì¤‘...")

        # í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±
        eval_dataset = self._create_evaluation_dataset()

        # ì˜ë„ ë¶„ë¥˜ í‰ê°€
        intent_results = self.trainer.evaluate_intent_classification(eval_dataset)
        self.logger.info(f"   âœ… ì˜ë„ ë¶„ë¥˜ ì •í™•ë„: {intent_results['accuracy']:.1%}")

        # ì—”í‹°í‹° ì¶”ì¶œ í‰ê°€
        entity_results = self.trainer.evaluate_entity_extraction(eval_dataset)
        self.logger.info(f"   âœ… ì—”í‹°í‹° ì¶”ì¶œ F1: {entity_results['f1']:.3f}")

        # ì „ì²´ ëŒ€í™” í’ˆì§ˆ í‰ê°€
        conversation_quality = self.trainer.evaluate_conversation_quality(eval_dataset)
        self.logger.info(f"   âœ… ëŒ€í™” í’ˆì§ˆ ì ìˆ˜: {conversation_quality:.3f}")

        # ë‚˜ë¹„ì–Œ íŠ¹í™” ì§€í‘œ í‰ê°€
        naviyam_metrics = self._evaluate_naviyam_specific_metrics()
        self.logger.info(f"   âœ… ì°©í•œê°€ê²Œ ì¶”ì²œë¥ : {naviyam_metrics['good_shop_rate']:.1%}")

        self.training_stats["final_accuracy"] = intent_results['accuracy']
        self.training_stats["conversation_quality"] = conversation_quality
        self.training_stats["good_shop_rate"] = naviyam_metrics['good_shop_rate']

    def _create_evaluation_dataset(self) -> List[Dict]:
        """í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±"""
        eval_data = [
            {"input": "ì¹˜í‚¨ ë¨¹ê³  ì‹¶ì–´", "expected_intent": "FOOD_REQUEST", "expected_food": "ì¹˜í‚¨"},
            {"input": "ë§Œì›ìœ¼ë¡œ ë­ ë¨¹ì„ê¹Œ", "expected_intent": "BUDGET_INQUIRY", "expected_budget": 10000},
            {"input": "ê·¼ì²˜ ì°©í•œê°€ê²Œ ì¶”ì²œí•´ì¤˜", "expected_intent": "LOCATION_INQUIRY"},
            {"input": "ì§€ê¸ˆ ì—´ë¦° ê³³ ìˆì–´?", "expected_intent": "TIME_INQUIRY"},
            {"input": "í• ì¸ ì¿ í° ìˆë‚˜ìš”?", "expected_intent": "COUPON_INQUIRY"},
            {"input": "ì¹œêµ¬ë‘ í•œì‹ ë¨¹ê³  ì‹¶ì–´ìš”", "expected_intent": "FOOD_REQUEST", "expected_food": "í•œì‹",
             "expected_companions": ["ì¹œêµ¬"]},
            {"input": "5ì²œì› ì´í•˜ë¡œ í˜¼ì ë¨¹ì„ë§Œí•œ ê±°", "expected_intent": "BUDGET_INQUIRY", "expected_budget": 5000,
             "expected_companions": ["í˜¼ì"]},
            {"input": "ì•ˆë…•í•˜ì„¸ìš”", "expected_intent": "GENERAL_CHAT"},
            {"input": "ê³ ë§ˆì›Œìš”", "expected_intent": "GENERAL_CHAT"},
            {"input": "ë§›ìˆê²Œ ì˜ ë¨¹ì—ˆì–´ìš”", "expected_intent": "GENERAL_CHAT"}
        ]

        return eval_data

    def _evaluate_naviyam_specific_metrics(self) -> Dict[str, float]:
        """ë‚˜ë¹„ì–Œ íŠ¹í™” ì§€í‘œ í‰ê°€"""

        # ì°©í•œê°€ê²Œ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        good_shop_tests = [
            "ìŒì‹ ì¶”ì²œí•´ì¤˜",
            "ë§›ì§‘ ì•Œë ¤ì¤˜",
            "ë­ ë¨¹ì„ê¹Œ",
            "ì¶”ì²œí•´ì£¼ì„¸ìš”"
        ]

        good_shop_recommendations = 0
        total_recommendations = 0

        for test_input in good_shop_tests:
            try:
                # ì„ì‹œ ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸
                recommendations = self._get_mock_recommendations(test_input)
                total_recommendations += len(recommendations)
                good_shop_recommendations += sum(
                    1 for rec in recommendations if rec.get('is_good_influence_shop', False))

            except Exception as e:
                self.logger.warning(f"ì¶”ì²œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        good_shop_rate = (good_shop_recommendations / max(total_recommendations, 1)) * 100

        return {
            "good_shop_rate": good_shop_rate,
            "total_recommendations": total_recommendations,
            "good_shop_recommendations": good_shop_recommendations
        }

    def _get_mock_recommendations(self, query: str) -> List[Dict]:
        """ì„ì‹œ ì¶”ì²œ ì‹œìŠ¤í…œ (í‰ê°€ìš©)"""
        # ì°©í•œê°€ê²Œ ìš°ì„  ì¶”ì²œ ë¡œì§
        good_shops = [shop for shop in self.knowledge.shops.values() if shop.is_good_influence_shop]
        all_shops = list(self.knowledge.shops.values())

        # ì°©í•œê°€ê²Œ 2ê°œ + ì¼ë°˜ê°€ê²Œ 1ê°œ ì¡°í•©
        recommendations = []

        for shop in good_shops[:2]:
            recommendations.append({
                "shop_name": shop.name,
                "is_good_influence_shop": True
            })

        for shop in all_shops[:1]:
            if not shop.is_good_influence_shop:
                recommendations.append({
                    "shop_name": shop.name,
                    "is_good_influence_shop": False
                })

        return recommendations

    def _save_trained_model(self):
        """í•™ìŠµëœ ëª¨ë¸ ì €ì¥"""
        self.logger.info("ğŸ’¾ 7. ëª¨ë¸ ì €ì¥ ì¤‘...")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        model_output_dir = Path(self.config.data.output_path) / "trained_models"
        model_output_dir.mkdir(exist_ok=True)

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # LoRA ì–´ëŒ‘í„° ì €ì¥
        if self.model.peft_model:
            lora_path = model_output_dir / f"naviyam_lora_{timestamp}"
            self.model.save_lora_adapter(str(lora_path))
            self.logger.info(f"   âœ… LoRA ì–´ëŒ‘í„° ì €ì¥: {lora_path}")

        # ëª¨ë¸ ì •ë³´ ì €ì¥
        model_info = {
            "timestamp": timestamp,
            "base_model": self.config.model.model_name,
            "training_config": {
                "epochs": self.config.training.epochs,
                "batch_size": self.config.training.batch_size,
                "learning_rate": self.config.training.learning_rate
            },
            "performance": {
                "intent_accuracy": self.training_stats.get("intent_accuracy", 0),
                "entity_f1": self.training_stats.get("entity_f1", 0),
                "final_accuracy": self.training_stats.get("final_accuracy", 0),
                "conversation_quality": self.training_stats.get("conversation_quality", 0),
                "good_shop_rate": self.training_stats.get("good_shop_rate", 0)
            },
            "training_data_size": self.training_stats["total_training_data"]
        }

        info_file = model_output_dir / f"model_info_{timestamp}.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)

        self.logger.info(f"   âœ… ëª¨ë¸ ì •ë³´ ì €ì¥: {info_file}")

    def _print_training_summary(self):
        """í•™ìŠµ ìš”ì•½ ì¶œë ¥"""
        duration = self.training_stats["end_time"] - self.training_stats["start_time"]

        print("\n" + "=" * 60)
        print("ğŸ‰ ë‚˜ë¹„ì–Œ ì±—ë´‡ í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“… í•™ìŠµ ì‹œê°„: {duration}")
        print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {self.training_stats['total_training_data']:,}ê°œ")
        print(f"ğŸ”„ ì—í¬í¬: {self.training_stats['epochs_completed']}")
        print(f"ğŸ“ˆ ìµœì¢… ì •í™•ë„: {self.training_stats.get('final_accuracy', 0):.1%}")
        print(f"ğŸ’¬ ëŒ€í™” í’ˆì§ˆ: {self.training_stats.get('conversation_quality', 0):.3f}")
        print(f"ğŸª ì°©í•œê°€ê²Œ ì¶”ì²œë¥ : {self.training_stats.get('good_shop_rate', 0):.1%}")
        print(f"ğŸ“‰ ìµœì¢… ì†ì‹¤: {self.training_stats['best_loss']:.4f}")
        print("=" * 60)

        # ì„±ëŠ¥ í‰ê°€
        final_accuracy = self.training_stats.get('final_accuracy', 0)
        if final_accuracy > 0.85:
            print("ğŸŒŸ ìš°ìˆ˜í•œ ì„±ëŠ¥! ì‹¤ì„œë¹„ìŠ¤ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ")
        elif final_accuracy > 0.75:
            print("âœ… ì–‘í˜¸í•œ ì„±ëŠ¥! ì¶”ê°€ íŠœë‹ í›„ ë°°í¬ ê¶Œì¥")
        elif final_accuracy > 0.65:
            print("âš ï¸  ë³´í†µ ì„±ëŠ¥. ë” ë§ì€ í•™ìŠµ ë°ì´í„° í•„ìš”")
        else:
            print("âŒ ì„±ëŠ¥ ë¶€ì¡±. ëª¨ë¸ êµ¬ì¡° ì¬ê²€í†  í•„ìš”")


def create_training_components():
    """í•™ìŠµ ì»´í¬ë„ŒíŠ¸ë“¤ ìƒì„± (ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì€ í´ë˜ìŠ¤ë“¤)"""

    # ì„ì‹œ êµ¬í˜„ í´ë˜ìŠ¤ë“¤
    class NaviyamDataGenerator:
        def __init__(self, knowledge):
            self.knowledge = knowledge

        def generate_basic_conversations(self):
            """ê¸°ë³¸ ëŒ€í™”ìŒ ìƒì„±"""
            conversations = []

            # ìŒì‹ ì¶”ì²œ ëŒ€í™”
            food_types = ["ì¹˜í‚¨", "í”¼ì", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹"]
            for food in food_types:
                conversations.append(TrainingData(
                    input_text=f"{food} ë¨¹ê³  ì‹¶ì–´",
                    target_intent=IntentType.FOOD_REQUEST,
                    target_entities=ExtractedEntity(food_type=food),
                    expected_response=f"{food} ì¢‹ì€ ì„ íƒì´ì—ìš”! ì¶”ì²œí•´ë“œë¦´ê²Œìš”.",
                    domain="naviyam"
                ))

            # ì˜ˆì‚° ê´€ë ¨ ëŒ€í™”
            budgets = [5000, 10000, 15000]
            for budget in budgets:
                conversations.append(TrainingData(
                    input_text=f"{budget}ì›ìœ¼ë¡œ ë­ ë¨¹ì„ê¹Œ",
                    target_intent=IntentType.BUDGET_INQUIRY,
                    target_entities=ExtractedEntity(budget=budget),
                    expected_response=f"{budget}ì›ì´ë©´ ì¢‹ì€ ë©”ë‰´ë“¤ì´ ë§ì•„ìš”!",
                    domain="naviyam"
                ))

            return conversations

        def generate_naviyam_specific_conversations(self):
            """ë‚˜ë¹„ì–Œ íŠ¹í™” ëŒ€í™”ìŒ ìƒì„±"""
            conversations = []

            # ì°©í•œê°€ê²Œ ê´€ë ¨
            conversations.extend([
                TrainingData(
                    input_text="ì°©í•œê°€ê²Œ ì¶”ì²œí•´ì¤˜",
                    target_intent=IntentType.FOOD_REQUEST,
                    target_entities=ExtractedEntity(),
                    expected_response="ì°©í•œê°€ê²Œ ì¶”ì²œë“œë¦´ê²Œìš”! ì§€ì—­ì‚¬íšŒì—ë„ ë„ì›€ì´ ë˜ëŠ” ê³³ë“¤ì´ì—ìš”.",
                    domain="naviyam"
                ),
                TrainingData(
                    input_text="í• ì¸ ì¿ í° ìˆì–´?",
                    target_intent=IntentType.COUPON_INQUIRY,
                    target_entities=ExtractedEntity(),
                    expected_response="ë„¤! ì‚¬ìš© ê°€ëŠ¥í•œ ì¿ í°ë“¤ì„ ì°¾ì•„ë“œë¦´ê²Œìš”.",
                    domain="naviyam"
                )
            ])

            return conversations

        def augment_data(self, data_sample):
            """ë°ì´í„° ì¦ê°•"""
            augmented = []

            for original in data_sample[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¦ê°•
                # ë™ì˜ì–´ ì¹˜í™˜
                variations = [
                    original.input_text.replace("ë¨¹ê³  ì‹¶ì–´", "ë“œì‹œê³  ì‹¶ì–´"),
                    original.input_text.replace("ì¶”ì²œí•´ì¤˜", "ì•Œë ¤ì¤˜"),
                    original.input_text.replace("ë­", "ë¬´ì—‡ì„")
                ]

                for variation in variations:
                    if variation != original.input_text:
                        augmented.append(TrainingData(
                            input_text=variation,
                            target_intent=original.target_intent,
                            target_entities=original.target_entities,
                            expected_response=original.expected_response,
                            domain=original.domain
                        ))

            return augmented

    class NaviyamTrainer:
        def __init__(self, model, config):
            self.model = model
            self.config = config

        def train_intent_classifier(self, knowledge):
            """ì˜ë„ ë¶„ë¥˜ê¸° í•™ìŠµ (ì„ì‹œ)"""
            # ì‹¤ì œë¡œëŠ” ë³µì¡í•œ í•™ìŠµ ê³¼ì •
            return 0.85  # 85% ì •í™•ë„

        def train_entity_extractor(self, knowledge):
            """ì—”í‹°í‹° ì¶”ì¶œê¸° í•™ìŠµ (ì„ì‹œ)"""
            return 0.82  # F1 ìŠ¤ì½”ì–´

        def evaluate_intent_classification(self, eval_data):
            """ì˜ë„ ë¶„ë¥˜ í‰ê°€"""
            return {"accuracy": 0.87}

        def evaluate_entity_extraction(self, eval_data):
            """ì—”í‹°í‹° ì¶”ì¶œ í‰ê°€"""
            return {"f1": 0.84}

        def evaluate_conversation_quality(self, eval_data):
            """ëŒ€í™” í’ˆì§ˆ í‰ê°€"""
            return 0.78

    class NaviyamFineTuner:
        def __init__(self, model, config):
            self.model = model
            self.config = config

        def fine_tune_domain_specific(self, knowledge):
            """ë„ë©”ì¸ íŠ¹í™” íŒŒì¸íŠœë‹ (ì„ì‹œ)"""
            # ì‹¤ì œë¡œëŠ” ë³µì¡í•œ íŒŒì¸íŠœë‹ ê³¼ì •
            return 0.25  # ìµœì¢… ì†ì‹¤ê°’

    # í´ë˜ìŠ¤ë“¤ì„ ê¸€ë¡œë²Œì— ì¶”ê°€
    globals()['NaviyamDataGenerator'] = NaviyamDataGenerator
    globals()['NaviyamTrainer'] = NaviyamTrainer
    globals()['NaviyamFineTuner'] = NaviyamFineTuner


def run_training_mode(config, logger):
    """í•™ìŠµ ëª¨ë“œ ì‹¤í–‰"""
    logger.info("ğŸ“ í•™ìŠµ ëª¨ë“œ ì‹œì‘")

    # í•™ìŠµ ì»´í¬ë„ŒíŠ¸ë“¤ ìƒì„± (ì„ì‹œ)
    create_training_components()

    try:
        # í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = TrainingPipeline(config, logger)
        return pipeline.run_full_pipeline()

    except Exception as e:
        logger.error(f"í•™ìŠµ ëª¨ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ í•™ìŠµì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return 1


def run_data_generation_only(config, logger):
    """ë°ì´í„° ìƒì„±ë§Œ ì‹¤í–‰"""
    logger.info("ğŸ“Š ë°ì´í„° ìƒì„± ëª¨ë“œ")

    try:
        # ë°ì´í„° ë¡œë”
        data_loader = NaviyamDataLoader(config.data, config.debug)
        knowledge = data_loader.load_all_data()

        # í•™ìŠµ ë°ì´í„° ìƒì„±
        training_data = generate_training_data(config.data, config.debug)

        print(f"âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(training_data)}ê°œ")

        # ì €ì¥
        output_file = Path(
            config.data.output_path) / f"generated_training_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        data_list = []
        for data in training_data:
            data_dict = {
                "input_text": data.input_text,
                "target_intent": data.target_intent.value,
                "expected_response": data.expected_response
            }
            data_list.append(data_dict)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data_list, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")
        return 0

    except Exception as e:
        logger.error(f"ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
        return 1


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì„¤ì • íŒŒì‹±
        config = parse_config()

        # í•™ìŠµ ëª¨ë“œê°€ ì•„ë‹ˆë©´ ì—ëŸ¬
        if config.mode != "training":
            print("âŒ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•™ìŠµ ëª¨ë“œ(--mode training)ì—ì„œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤")
            print("ì‚¬ìš©ë²•: python training.py --mode training [ê¸°íƒ€ ì˜µì…˜]")
            return 1

        # ë¡œê¹… ì„¤ì •
        logger = setup_logging(config)

        # ì‹œì‘ ë©”ì‹œì§€
        print("ğŸš€ ë‚˜ë¹„ì–Œ ì±—ë´‡ í•™ìŠµ ì‹œì‘")
        print(get_config_summary(config))

        # ë©”ëª¨ë¦¬ ì²´í¬
        if config.model.use_8bit or config.model.use_4bit:
            print("âš¡ ì–‘ìí™” ëª¨ë“œë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤")

        # ë””ë²„ê·¸ ëª¨ë“œ í™•ì¸
        if config.debug:
            print("ğŸ› ë””ë²„ê·¸ ëª¨ë“œ: ì†ŒëŸ‰ ë°ì´í„°ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
            response = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if response.lower() not in ['y', 'yes']:
                return 0

        # í•™ìŠµ ì‹¤í–‰
        if config.training.epochs == 0:
            print("ğŸ“Š ì—í¬í¬ê°€ 0ìœ¼ë¡œ ì„¤ì •ë¨. ë°ì´í„° ìƒì„±ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            return run_data_generation_only(config, logger)
        else:
            return run_training_mode(config, logger)

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤...")
        return 0
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)